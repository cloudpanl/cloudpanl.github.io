<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>每天进步一点点……</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-03-19T14:03:11.860Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Cloudpanl</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>浅谈服务治理、微服务与Service Mesh（一）Dubbo的前世今生【转载】</title>
    <link href="http://yoursite.com/2018/03/19/dubbo-past-and-present.html"/>
    <id>http://yoursite.com/2018/03/19/dubbo-past-and-present.html</id>
    <published>2018-03-19T09:44:57.000Z</published>
    <updated>2018-03-19T14:03:11.860Z</updated>
    
    <content type="html"><![CDATA[<p>本系列文章将为大家介绍当下最流行的服务治理、微服务等相关内容，从服务治理、SOA、微服务到最新的服务网格（Service Mesh）进行综合介绍和分析。易商阜极自2017年便积极引进微服务的先进理念，运用在项目实践中，为项目集成带来了显著效果。本文将以Dubbo为例，向为大家介绍SOA、服务治理等概念，以及Dubbo的基础知识和最新发展情况。</p><h1 id="SOA与服务治理"><a href="#SOA与服务治理" class="headerlink" title="SOA与服务治理"></a>SOA与服务治理</h1><p>SOA（面向服务的体系结构）概念由来已久，在10多年前便开始进入到我们广大软件开发者的视线中。SOA是一种粗粒度、松耦合服务架构，服务之间通过简单、精确定义接口进行通讯，不涉及底层编程接口和通讯模型。SOA可以看作是B/S模型、Web Service技术之后的自然延伸。</p><p>服务治理，也称为SOA治理，是指用来管理SOA的采用和实现的过程。以下是在2006年时IBM对于服务治理要点的总结：</p><ul><li>服务定义（服务的范围、接口和边界）</li><li>服务部署生命周期（各个生命周期阶段）</li><li>服务版本治理（包括兼容性）</li><li>服务迁移（启用和退役）</li><li>服务注册中心（依赖关系）</li><li>服务消息模型（规范数据模型）</li><li>服务监视（进行问题确定）</li><li>服务所有权（企业组织）</li><li>服务测试（重复测试）</li><li>服务安全（包括可接受的保护范围）</li></ul><p>限于当时的技术发展水平，广大软件设计与开发人员对于SOA和服务治理的技术认知还主要停留在Web Service和ESB总线等技术和规范上，并没有真正在软件开发中得以充分落地。</p><h1 id="Dubbo开源"><a href="#Dubbo开源" class="headerlink" title="Dubbo开源"></a>Dubbo开源</h1><p>直到2011年10月27日，阿里巴巴开源了自己的SOA服务化治理方案的核心框架Dubbo，服务治理和SOA的设计理念开始逐渐在国内软件行业中落地，并被广泛应用。<br>Dubbo作为阿里巴巴内部的SOA服务化治理方案的核心框架，在2012年时已经每天为2000+个服务提供3,000,000,000+次访问量支持，并被广泛应用于阿里巴巴集团的各成员站点。Dubbo自2011年开源后，已被许多非阿里系公司使用，其中既有当当网、网易考拉等互联网公司，也有中国人寿、青岛海尔等传统企业。</p><h1 id="Dubbo简介"><a href="#Dubbo简介" class="headerlink" title="Dubbo简介"></a>Dubbo简介</h1><p>Dubbo是一个高性能服务框架，致力于提供高性能和透明化的RPC远程服务调用方案，以及SOA服务治理方案，使得应用可通过高性能RPC实现服务的输出和输入功能，和Spring框架可以无缝集成。</p><p>作为一个分布式服务框架，以及SOA治理方案，Dubbo其功能主要包括：高性能NIO通讯及多协议集成，服务动态寻址与路由，软负载均衡与容错，依赖分析与服务降级等。Dubbo最大的特点是按照分层的方式来架构，使用这种方式可以使各个层之间解耦合（或者最大限度地松耦合）。从服务模型的角度来看，Dubbo采用的是一种非常简单的模型，要么是提供方提供服务，要么是消费方消费服务，所以基于这一点可以抽象出服务提供方（Provider）和服务消费方（Consumer）两个角色。</p><p>Dubbo包含远程通讯、集群容错和自动发现三个核心部分。提供透明化的远程方法调用，实现像调用本地方法一样调用远程方法，只需简单配置，没有任何API侵入。同时具备软负载均衡及容错机制，可在内网替代F5等硬件负载均衡器，降低成本，减少单点。可以实现服务自动注册与发现，不再需要写死服务提供方地址，注册中心基于接口名查询服务提供者的IP地址，并且能够平滑添加或删除服务提供者。</p><p>下图来自从Dubbo官网，描述了服务注册中心、服务提供方、服务消费方、服务监控中心之间的调用关系，具体如下图所示：<br><img src="http://dockone.io/uploads/article/20180124/11a8ad251bf0ae6577eead936add06e7.png" alt=""></p><p>节点角色说明：<br><img src="http://dockone.io/uploads/article/20180124/2c69dfd83dd060315be04574dbcc48c9.png" alt=""></p><p>调用关系说明：</p><ol><li>服务容器负责启动，加载，运行服务提供者。</li><li>服务提供者在启动时，向注册中心注册自己提供的服务。</li><li>服务消费者在启动时，向注册中心订阅自己所需的服务。</li><li>注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。</li><li>服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。</li><li>服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。</li></ol><h1 id="Dubbo总体架构"><a href="#Dubbo总体架构" class="headerlink" title="Dubbo总体架构"></a>Dubbo总体架构</h1><p>Dubbo框架设计共划分了10层，最上面的Service层是留给实际使用Dubbo开发分布式服务的开发者实现业务逻辑的接口层。图中左边淡蓝背景的为服务消费方使用的接口，右边淡绿色背景的为服务提供方使用的接口，位于中轴线上的为双方都用到的接口。</p><p><img src="http://dockone.io/uploads/article/20180124/8349c5fc87fef048bb26ea6b277eee4d.png" alt=""></p><p>各层说明：</p><ul><li>Config配置层：对外配置接口，以ServiceConfig、ReferenceConfig为中心，可以直接初始化配置类，也可以通过Spring解析配置生成配置类。</li><li>Proxy服务代理层：服务接口透明代理，生成服务的客户端Stub和服务器端Skeleton，以ServiceProxy为中心，扩展接口为ProxyFactory。</li><li>Registry注册中心层：封装服务地址的注册与发现，以服务URL为中心，扩展接口为RegistryFactory、Registry、RegistryService。</li><li>Cluster路由层：封装多个提供者的路由及负载均衡，并桥接注册中心，以Invoker为中心，扩展接口为Cluster、Directory、Router、LoadBalance。</li><li>Monitor监控层：RPC调用次数和调用时间监控，以Statistics为中心，扩展接口为MonitorFactory、Monitor、MonitorService。</li><li>Protocol远程调用层：封将RPC调用，以Invocation、Result为中心，扩展接口为Protocol、Invoker、Exporter。</li><li>Exchange信息交换层：封装请求响应模式，同步转异步，以Request、Response为中心，扩展接口为Exchanger、ExchangeChannel、ExchangeClient、ExchangeServer。</li><li>Transport网络传输层：抽象MINA和Netty为统一接口，以Message为中心，扩展接口为Channel、Transporter、Client、Server、Codec。</li><li>Serialize数据序列化层：可复用的一些工具，扩展接口为Serialization、ObjectInput、ObjectOutput、ThreadPool。</li></ul><h1 id="模块分包"><a href="#模块分包" class="headerlink" title="模块分包"></a>模块分包</h1><p><img src="http://dockone.io/uploads/article/20180124/3b191f3699ee69601a87bb6f0864f18f.png" alt=""></p><p>各模块说明：</p><ul><li>dubbo-common公共逻辑模块：包括Util类和通用模型。</li><li>dubbo-remoting远程通讯模块：相当于Dubbo协议的实现，如果RPC用 RMI协议则不需要使用此包。</li><li>dubbo-rpc远程调用模块：抽象各种协议，以及动态代理，只包含一对一的调用，不关心集群的管理。</li><li>dubbo-cluster集群模块：将多个服务提供方伪装为一个提供方，包括：负载均衡、容错、路由等，集群的地址列表可以是静态配置的，也可以是由注册中心下发。</li><li>dubbo-registry注册中心模块：基于注册中心下发地址的集群方式，以及对各种注册中心的抽象。</li><li>dubbo-monitor监控模块：统计服务调用次数、调用时间的、调用链跟踪的服务。</li><li>dubbo-config配置模块：是Dubbo对外的API，用户通过Config使用Dubbo，隐藏Dubbo所有细节。</li><li>dubbo-container容器模块：是一个Standlone的容器，以简单的Main加载Spring启动，因为服务通常不需要Tomcat/JBoss等Web容器的特性，没必要用Web容器去加载服务。</li></ul><h1 id="协议支持"><a href="#协议支持" class="headerlink" title="协议支持"></a>协议支持</h1><ul><li>Dubbo协议（默认协议）</li><li>Hessian协议</li><li>HTTP协议</li><li>RMI协议</li><li>WebService协议</li><li>Thrift协议</li><li>Memcached协议</li><li>Redis协议</li></ul><h1 id="注册中心"><a href="#注册中心" class="headerlink" title="注册中心"></a>注册中心</h1><h2 id="（1）Multicast注册中心："><a href="#（1）Multicast注册中心：" class="headerlink" title="（1）Multicast注册中心："></a>（1）Multicast注册中心：</h2><p>Multicast注册中心不需要启动任何中心节点，只要广播地址一样，就可以互相发现。组播受网络结构限制，只适合小规模应用或开发阶段使用。组播地址段：224.0.0.0 - 239.255.255.255。</p><h2 id="（2）ZooKeeper注册中心（推荐）："><a href="#（2）ZooKeeper注册中心（推荐）：" class="headerlink" title="（2）ZooKeeper注册中心（推荐）："></a>（2）ZooKeeper注册中心（推荐）：</h2><p>ZooKeeper是Apacahe子项目，是一个树型的目录服务，支持变更推送，适合作为Dubbo服务的注册中心，可用于生产环境。</p><p><img src="http://dockone.io/uploads/article/20180124/fe00d79623628e628f64e13bba33616c.png" alt=""></p><p>对上图流程说明如下：</p><ol><li>服务提供者（Provider）启动时，向/dubbo/com.foo.BarService/providers目录下写入URL。</li><li>服务消费者（Consumer）启动时，订阅/dubbo/com.foo.BarService/providers目录下的URL，向/dubbo/com.foo.BarService/consumers目录下写入自己的URL。</li><li>监控中心（Monitor）启动时，订阅/dubbo/com.foo.BarService目录下的所有提供者和消费者URL。</li></ol><h2 id="（3）Redis注册中心："><a href="#（3）Redis注册中心：" class="headerlink" title="（3）Redis注册中心："></a>（3）Redis注册中心：</h2><p>阿里内部并没有采用Redis做为注册中心，而是使用自己实现的基于数据库的注册中心，即：Redis注册中心并没有在阿里内部长时间运行的可靠性保障，此Redis桥接实现只为开源版本提供，其可靠性依赖于Redis本身的可靠性。</p><h2 id="（4）Simple注册中心："><a href="#（4）Simple注册中心：" class="headerlink" title="（4）Simple注册中心："></a>（4）Simple注册中心：</h2><p>Simple注册中心本身就是一个普通的Dubbo服务，可以减少第三方依赖，使整体通讯方式一致。只是简单实现，不支持集群，可作为自定义注册中心的参考，但不适合直接用于生产环境。</p><h1 id="远程通信与信息交换"><a href="#远程通信与信息交换" class="headerlink" title="远程通信与信息交换"></a>远程通信与信息交换</h1><p>远程通信需要指定通信双方所约定的协议，在保证通信双方理解协议语义的基础上，还要保证高效、稳定的消息传输。Dubbo继承了当前主流的网络通信框架，主要包括如下几个：</p><ul><li>Mina</li><li>Netty（默认）</li><li>Grizzly</li></ul><h1 id="停止维护"><a href="#停止维护" class="headerlink" title="停止维护"></a>停止维护</h1><p>从2012年10月23日Dubbo 2.5.3发布后，在Dubbo开源将满一周年之际，阿里基本停止了对Dubbo的主要升级。只在之后的2013年和2014年更新过2次对Dubbo 2.4的维护版本，然后停止了所有维护工作。Dubbo对Srping的支持也停留在了Spring 2.5.6版本上。</p><h1 id="分支出现"><a href="#分支出现" class="headerlink" title="分支出现"></a>分支出现</h1><p>在阿里停止维护和升级Dubbo期间，当当网开始维护自己的Dubbo分支版本Dubbox，支持了新版本的Spring，并对外开源了Dubbox。同时，网易考拉也维护了自己的独立分支Dubbok，可惜并未对外开源。</p><h1 id="重获新生"><a href="#重获新生" class="headerlink" title="重获新生"></a>重获新生</h1><p>经过多年漫长的等待，随着微服务的火热兴起，在国内外开发者对阿里不再升级维护Dubbo的吐槽声中，阿里终于开始重新对Dubbo的升级和维护工作。在2017年9月7日 ，阿里发布了Dubbo的2.5.4版本，距离上一个版本2.5.3发布已经接近快5年时间了。在随后的几个月中，阿里Dubbo开发团队以差不多每月一版本的速度开始快速升级迭代，修补了Dubbo老版本多年来存在的诸多bug，并对Spring等组件的支持进行了全面升级。</p><h1 id="分支合并"><a href="#分支合并" class="headerlink" title="分支合并"></a>分支合并</h1><p>在2018年1月8日，Dubbo 2.6.0版本发布，新版本将之前当当网开源的Dubbo分支Dubbox进行了合并，实现了Dubbo版本的统一整合。</p><h1 id="Dubbo与Spring-Cloud"><a href="#Dubbo与Spring-Cloud" class="headerlink" title="Dubbo与Spring Cloud"></a>Dubbo与Spring Cloud</h1><p>阿里巴巴负责主导了 Dubbo 重启维护的研发工程师刘军在接受采访时表示：当前由于 RPC 协议、注册中心元数据不匹配等问题，在面临微服务基础框架选型时Dubbo与Spring Cloud是只能二选一，这也是为什么大家总是拿Dubbo和Spring Cloud做对比的原因之一。Dubbo之后会积极寻求适配到Spring Cloud生态，比如作为Spring Cloud的二进制通信方案来发挥Dubbo的性能优势，或者Dubbo通过模块化以及对http的支持适配到Spring Cloud。</p><h1 id="未来展望"><a href="#未来展望" class="headerlink" title="未来展望"></a>未来展望</h1><p>2018年1月8日，Dubbo创始人之一梁飞在Dubbo交流群里透露了Dubbo 3.0正在动工的消息。Dubbo 3.0内核与Dubbo 2.0完全不同，但兼容Dubbo 2.0。Dubbo 3.0将以Streaming为内核，不再是Dubbo时代的RPC，但是RPC会在Dubbo 3.0中变成远程Streaming对接的一种可选形态。Dubbo 3.0将支持可选Service Mesh，多加一层IPC，这主要是为了兼容老系统，而内部则会优先尝试内嵌模式。代理模式Ops可独立升级框架，减少业务侵入，而内嵌模式可以带业务测试、部署节点少、稳定性检测方便。同时，可以将Dubbo 3.0启动为独立进程，由dubbo-mesh进行IPC，路由、负载均衡和熔断机制将由独立进程控制。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>从 Dubbo 新版本的路线规划上可以看出，新版本的Dubbo在原有服务治理的功能基础上，将全面拥抱微服务和Service Mesh。同时，考虑到在阿里云已经有了Dubbo的商业版本，在未来一段时间内，Dubbo的更新与维护应该不会再长时间中断。在我们进行服务治理以及微服务架构设计时，新版本Dubbo对我们广大开发者来说都将会是一个不错的选择。</p><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><ul><li><a href="http://dubbo.io" target="_blank" rel="noopener">http://dubbo.io</a></li><li><a href="https://github.com/alibaba/dubbo" target="_blank" rel="noopener">https://github.com/alibaba/dubbo</a></li><li><a href="http://shiyanjun.cn/archives/325.html" target="_blank" rel="noopener">http://shiyanjun.cn/archives/325.html</a></li><li><a href="http://mp.weixin.qq.com/s/eVYx-tUIMYtAk5wP-qkdkw" target="_blank" rel="noopener">http://mp.weixin.qq.com/s/eVYx-tUIMYtAk5wP-qkdkw</a></li></ul><p>原文链接：<a href="https://mp.weixin.qq.com/s?__biz=MjM5MDM3NDY1NQ==&amp;mid=2651112485&amp;idx=2&amp;sn=584285b2c52e59a4957bf50079ce41e4&amp;chksm=bdb5abb58ac222a3b1a62ae9d40a66a14e05b9bc101f50a30abfcf8e38a8e0a6ac233e985a8c&amp;mpshare=1&amp;scene=1&amp;srcid=0124lduJyZ5omV9YJHbcTVSk&amp;pass_ticket=zauggU5Vx7VPre9Q8e8%2BSi0sDlvU6Gr3Jg%2F%2BrZ9BVX5EtWQ9Mf%2B%2Bch2jYuJEjOeL#rd" target="_blank" rel="noopener">浅谈服务治理、微服务与Service Mesh（一）Dubbo的前世今生</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本系列文章将为大家介绍当下最流行的服务治理、微服务等相关内容，从服务治理、SOA、微服务到最新的服务网格（Service Mesh）进行综合介绍和分析。易商阜极自2017年便积极引进微服务的先进理念，运用在项目实践中，为项目集成带来了显著效果。本文将以Dubbo为例，向为大
      
    
    </summary>
    
      <category term="微服务" scheme="http://yoursite.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="Dubbo,Service Mesh,微服务,ZooKeeper" scheme="http://yoursite.com/tags/Dubbo-Service-Mesh-%E5%BE%AE%E6%9C%8D%E5%8A%A1-ZooKeeper/"/>
    
  </entry>
  
  <entry>
    <title>如何选择 Linux 上的跟踪器</title>
    <link href="http://yoursite.com/2018/03/18/choosing-a-linux-tracer.html"/>
    <id>http://yoursite.com/2018/03/18/choosing-a-linux-tracer.html</id>
    <published>2018-03-18T14:38:01.000Z</published>
    <updated>2018-03-18T15:28:12.985Z</updated>
    
    <content type="html"><![CDATA[<p>tracer是一个高级的性能分析和诊断工具，但是不要让这名词唬住你，如果你使用过 strace 和 tcpdump，其实你就已经使用过跟踪器了。系统跟踪器可以获取更多的系统调用和数据包。它们通常能跟踪任意的内核和应用程序。</p><p>有太多的 Linux 跟踪器可以选择。每一种都有其官方的（或非官方的）的卡通的独角兽吉祥物，足够撑起一台”儿童剧”了。</p><p><img src="https://res.cloudinary.com/cloudpanl/image/upload/v1521384181/choosing-a-linux-tracer-1.jpg" alt=""></p><p>那么我们应该使用哪个跟踪器呢？</p><p>可分为两类：大多数人和性能/内核工程师。</p><h1 id="对于大多数人"><a href="#对于大多数人" class="headerlink" title="对于大多数人"></a>对于大多数人</h1><p>大多数人 (开发者，系统管理员，开发管理者，运维人员，评测人员，等等) 不关心系统追踪器的细节。下面是对于追踪器你应该知道和做的：</p><h2 id="1-使用-perf-events-分析-CPU-性能"><a href="#1-使用-perf-events-分析-CPU-性能" class="headerlink" title="1. 使用 perf_events 分析 CPU 性能"></a>1. 使用 perf_events 分析 CPU 性能</h2><p>使用 perf_events 做 CPU 性能分析。性能指标可以使用 <a href="http://www.brendangregg.com/FlameGraphs/cpuflamegraphs.html" target="_blank" rel="noopener">flame graph</a> 等工具做可视化。</p><pre><code>git clone --depth 1 https://github.com/brendangregg/FlameGraphperf record -F 99 -a -g -- sleep 30perf script | ./FlameGraph/stackcollapse-perf.pl | ./FlameGraph/flamegraph.pl &gt; perf.svg</code></pre><p>Linux perf_events (又称 “perf”，同命令名) 是 Linux 用户的官方跟踪器和性能分析器。内置于内核代码，有很好维护（近来获得快速增强），通常通过 linux-tools-common 软件包安装。</p><p>perf 有很多功能，如果只能推荐一个，我选择 CPU 性能分析。尽管这只是采样，而不是从技术上追踪事件。最难的部分是获取完整的栈和信息，我为 java 和 node.js 做的一个演讲 <a href="http://www.brendangregg.com/blog/2015-02-27/linux-profiling-at-netflix.html" target="_blank" rel="noopener">Linux Profiling at Netflix</a> 中已经说过这个问题。</p><p><img src="https://res.cloudinary.com/cloudpanl/image/upload/v1521385307/choosing-a-linux-tracer-2.png" alt=""></p><h2 id="2-了解其他的跟踪器"><a href="#2-了解其他的跟踪器" class="headerlink" title="2. 了解其他的跟踪器"></a>2. 了解其他的跟踪器</h2><p>正如我一个朋友说的：“你不需要知道如何操作 X 射线机器，但是一旦你吞了一枚硬币，你得知道这得去做 X 射线”，你应该了解各种跟踪器都能做什么，这样就能在你工作中真正需要跟踪器的时候，你既可以选择稍后学习使用，也可以雇相应的人来完成。</p><p>简短来说：几乎所有的东西都可以使用跟踪器来进行分析和跟踪。如，文件系统内部、TCP/IP 过程、设备驱动、应用程序内部。可以看一下我的个人网站上关于 <a href="http://lwn.net/Articles/608497/" target="_blank" rel="noopener">ftrace</a> 的文章，还有我写的关于 <a href="http://www.brendangregg.com/perf.html" target="_blank" rel="noopener">perf_events</a> 文档介绍，可以做为一个追踪（或者性能分析）的例子。</p><h2 id="3-寻求前端支持工具"><a href="#3-寻求前端支持工具" class="headerlink" title="3. 寻求前端支持工具"></a>3. 寻求前端支持工具</h2><p>如果你正想买一个能支持跟踪 Linux 的性能分析工具（有许多卖这类工具的公司）。想像一下，只需要直接点击一下界面就能“洞察”整个系统内核，包括隐藏的不同堆栈位置的热图，我在 <a href="http://www.brendangregg.com/blog/2015-06-23/netflix-instance-analysis-requirements.html" target="_blank" rel="noopener">Monitorama talk</a> 中介绍了一个这样带图形界面的工具。</p><p>我开源了一些我自己开发的前端工具，尽管只是命令行界面而不是图形界面。这些工具也会让人们更加快速容易的使用跟踪器。比如下面的例子，用我的 perf_tool，跟踪一个新进程:</p><pre><code># ./execsnoopTracing exec()s. Ctrl-C to end.   PID   PPID ARGS 22898  22004 man ls 22905  22898 preconv -e UTF-8 22908  22898 pager -s 22907  22898 nroff -mandoc -rLL=164n -rLT=164n -Tutf8[...]</code></pre><p>在 Netflix 上，我们创建了一个 <a href="http://techblog.netflix.com/2015/04/introducing-vector-netflixs-on-host.html" target="_blank" rel="noopener">Vector</a>，一个分析工具的实例，同时也是 Linux 上的跟踪器的最终前端。</p><h1 id="对于性能-内核工程师"><a href="#对于性能-内核工程师" class="headerlink" title="对于性能/内核工程师"></a>对于性能/内核工程师</h1><p>我们的工作变的越来越困难，很多的人会问我们怎么样去追踪，哪种跟踪器可以用！为了正确理解一个跟踪器，你经常需要花上至少100个小时才能做到。理解所有的 linux 跟踪器去做出理性的选择是一个浩大的工程。（我可能是唯一一个快做到这件事情的人）</p><p><img src="https://res.cloudinary.com/cloudpanl/image/upload/v1521385735/choosing-a-linux-tracer-3.jpg" alt=""></p><p>这里是我的建议，可以二选其一：</p><p>A) 选中一个全能的跟踪器，并且使它标准化，这将涉及花费大量的时间去弄清楚它在测试环境中的细微差别和安全性。我现在推荐 SystemTap 的最新版本（可以从源代码构建）。我知道有些公司已经选用 LTTng，而且他们用的很好，尽管它不是非常的强大（虽然它更安全）。如果 Sysdig 可以增加追踪点tracepoint或者 kprobes，可以做为另一个候选。 </p><p>B) 遵循我上面提供的流程图，它将意味着尽可能更多的使用 ftrace 或者 perf_event， 并整合 eBPF，之后其他的跟踪器像 SystemTap/LTTng 会去填补剩下的空白。 这就是我目前在 Netflix 做的工作。</p><h1 id="对跟踪器的评价"><a href="#对跟踪器的评价" class="headerlink" title="对跟踪器的评价"></a>对跟踪器的评价</h1><h2 id="1-ftrace"><a href="#1-ftrace" class="headerlink" title="1. ftrace"></a>1. ftrace</h2><p>我喜欢用 ftrace，它是内核 hacker 的首选，内置于系统内核，可以使用跟踪点（静态检查点），能调用内核 kprobes 和 uprobes 调试工具。并且提供几个这样的功能：带可选过滤器和参数的事件追踪功能；在内核中进行统计的事件计数和定时功能；还有函数流程遍历的功能。可以看一下内核代码中 <a href="https://www.kernel.org/doc/Documentation/trace/ftrace.txt" target="_blank" rel="noopener">ftrace.txt</a> 例子了解一下。ftrace 由 /sys 控制，仅支持单一的 root 用户使用（但是你可以通过缓冲区实例改成支持多用户）。某些时候 ftrace 的操作界面非常繁琐，但是的确非常“hack”，而且它有前端界面。ftace 的主要作者 Steven Rostedt 创建了 trace-cmd 命令工具，而我创建了 perf 的工具集。我对这个工具最大的不满就是它不可编程。举例来说，你不能保存和获取时间戳，不能计算延迟，不能把这些计算结果保存成直方图的形式。你需要转储事件至用户层，并且花一些时间去处理结果。ftrace 可以通过 eBPF 变成可编程的。</p><h2 id="2-perf-events"><a href="#2-perf-events" class="headerlink" title="2. perf_events"></a>2. perf_events</h2><p>perf_events 是 Linux 用户的主要跟踪工具，它内置在内核源码中，通常通过 linux-tools-commom 安装。也称为“perf”，即其前端工具名称，它通常用来跟踪和转储信息到一个叫做 perf.data 的文件中，perf.data 文件相当于一个动态的缓冲区，用来保存之后需要处理的结果。ftrace 能做到的，perf_events 大都也可以做到，perf-events 不能做函数流程遍历，少了一点儿“hack”劲儿（但是对于安全/错误检查有更好的支持）。它可以进行 CPU 分析和性能统计，用户级堆栈解析，也可以使用对于跟踪每行局部变量产生的调试信息。它也支持多用户并发操作。和 ftrace 一样也不支持可编程。如果要我只推荐一款跟踪器，那一定是 perf 了。它能解决众多问题，并且它相对较安全。</p><h2 id="3-eBPF"><a href="#3-eBPF" class="headerlink" title="3. eBPF"></a>3. eBPF</h2><p>extended Berkeley Packet Filter（eBPF）是一个可以在事件上运行程序的高效内核虚拟机（JIT）。它可能最终会提供 ftrace 和 perf_events 的内核编程，并强化其他的跟踪器。这是 Alexei Starovoitov 目前正在开发的，还没有完全集成，但是从4.1开始已经对一些优秀的工具有足够的内核支持了，如块设备 I/O 的延迟热图。可参考其主要作者 Alexei Starovoitov 的 <a href="http://www.phoronix.com/scan.php?page=news_item&amp;px=BPF-Understanding-Kernel-VM" target="_blank" rel="noopener">BPF slides</a> 和 <a href="https://github.com/torvalds/linux/tree/master/samples/bpf" target="_blank" rel="noopener">eBPF samples</a>。</p><h2 id="4-SystemTap"><a href="#4-SystemTap" class="headerlink" title="4. SystemTap"></a>4. SystemTap</h2><p><a href="https://sourceware.org/systemtap/wiki" target="_blank" rel="noopener">SystemTap</a> 是最强大的跟踪器。它能做所有事情，如概要分析，跟踪点，探针，uprobes（来自SystemTap），USDT 和内核编程等。它将程序编译为内核模块，然后加载，这是一种获取安全的巧妙做法。它也是从 tree 发展而来，过去有很多问题（崩溃或冻结）。很多不是 SystemTap 本身的错——它常常是第一个使用某个内核追踪功能，也是第一个碰到 bug 的。SystemTap 的最新版本好多了（必须由源代码编译），但是很多人仍然会被早期版本吓到。如果你想用它，可先在测试环境中使用，并与 irc.freenode.net 上 的 #systemtap 开发人员交流。（Netflix 有容错机制，我们已经使用了 SystemTap，但是可能我们考虑的安全方面的问题比你们少。）我最大的不满是，它似乎认为你应该有内核 debug 信息，但是经常没有。实际上没有它也能做很多事情，但是缺少文档和例子（我必须自己全靠自己开始学习）。</p><h2 id="5-LTTng"><a href="#5-LTTng" class="headerlink" title="5. LTTng"></a>5. LTTng</h2><p>LTTng 优化了事件采集，这比其他跟踪器做得好，它也支持几种事件类型，包括 USTD。它从 tree 发展而来，它的核心很简单：通过一组小规模的固定指令集将事件写入追踪缓冲区，这种方式使它安全、快速，缺点是它没有内核编码的简单途径。我一直听说这不是一个大问题，因为尽管需要后期处理，它也已经优化到可以充分的度量。此外，它还首创了一个不同的分析技术，对所有关注事件的更多黑盒记录将能够稍后以 GUI 的方式进行研究。我关心的是前期没有考虑到要录制的事件缺失问题如何解决，但我真正要做的是花更多时间来看它在实践中用的怎么样。这是我花的时间最少的一个跟踪器（没有什么特殊原因）。</p><h2 id="6-Ktap"><a href="#6-Ktap" class="headerlink" title="6. Ktap"></a>6. Ktap</h2><p>ktap 是一款前景很好的跟踪器，它使用内核中的 lua 虚拟机处理，在没有调试信息的情况下在嵌入式设备上运行的很好。这让它得到了关注，并在有一段时间似乎超过了 Linux 上所有的追踪器。然后 eBPF 开始集成到内核了，而 ktap 的集成会在可以使用 eBPF 替代它自己的虚拟机后才开始。因为 eBPF 仍将持续集成几个月，ktap 开发者要继续等上一段时间。我希望今年晚些时候它能重新开发。</p><h2 id="7-dtrace4linux"><a href="#7-dtrace4linux" class="headerlink" title="7. dtrace4linux"></a>7. dtrace4linux</h2><p><a href="http://www.oschina.net/p/dtrace4linux" target="_blank" rel="noopener">dtrace4linux</a> 主要是 Paul Fox 一个人在业余时间完成的，它是 Sun DTrace 的 Linux 版本。它引人瞩目，已经有一些供应器provider可以工作，但是从某种程度上来说还不完整，更多的是一种实验性的工具（不安全）。我认为，顾忌到许可证问题，人们会小心翼翼的为 dtrace4linux 贡献代码：由于当年 Sun 开源DTrace 使用的是 CDDL 协议，而 dtrace4linux 也不大可能最终进入 Linux kernel。Paul 的方法很可能会使其成为一个 add-on。我很乐意看到 Linux 平台上的 DTrace 和这个项目的完成，我认为当我加入 Netflix 后将会花些时间来协助完成这个项目。然而，我还是要继续使用内置的跟踪器，如 ftrace 和 perf_events。</p><h2 id="8-OL-DTrace"><a href="#8-OL-DTrace" class="headerlink" title="8. OL DTrace"></a>8. OL DTrace</h2><p><a href="http://docs.oracle.com/cd/E37670_01/E38608/html/index.html" target="_blank" rel="noopener">Oracle Linux DTrace</a> 为了将 DTrace 引入 Linux，特别是为 Oracle Linux，做出了很大的努力。这些年来发布的多个版本表明了它的稳定进展。开发者们以一种对这个项目的前景看好的态度谈论着改进 DTrace 测试套件。很多有用的 供应器provider 已经完成了，如：syscall, profile, sdt, proc, sched 以及 USDT。我很期待 fbt（function boundary tracing，用于内核动态跟踪）的完成，它是 Linux 内核上非常棒的 供应器provider。OL DTrace 最终的成功将取决于人们对运行 Oracle Linux（为技术支持付费）有多大兴趣，另一方面取决于它是否完全开源：它的内核元件是开源的，而我没有看到它的用户级别代码。</p><h2 id="9-sysdig"><a href="#9-sysdig" class="headerlink" title="9. sysdig"></a>9. sysdig</h2><p><a href="http://www.sysdig.org/" target="_blank" rel="noopener">sysdig</a> 是一个使用类 tcpdump 语法在系统事件上操作的新跟踪器，它使用 lua 进行后期处理。它很优秀，它见证了系统跟踪领域的变革。它的局限性在于它只在当前进行系统调用，将所有事件转储为用户级别用于后期处理。你可以使用系统调用做很多事情，然而我还是很希望它能支持跟踪点、kprobe 和 uprobe。我还期待它能支持 eBPF 做内核摘要。目前，sysdig 开发者正在增加容器支持。留意这些内容。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;tracer是一个高级的性能分析和诊断工具，但是不要让这名词唬住你，如果你使用过 strace 和 tcpdump，其实你就已经使用过跟踪器了。系统跟踪器可以获取更多的系统调用和数据包。它们通常能跟踪任意的内核和应用程序。&lt;/p&gt;
&lt;p&gt;有太多的 Linux 跟踪器可以选择
      
    
    </summary>
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
  </entry>
  
</feed>
