<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="panliang's blog."><meta name="keywords" content="Linux,Kubernetes,Docker,Microservices"><title>Kubernetes 排错指南：POD【转载】 | 每天进步一点点……</title><link rel="stylesheet" type="text/css" href="//fonts.neworld.org/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.1"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.1"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Kubernetes 排错指南：POD【转载】</h1><a id="logo" href="/.">每天进步一点点……</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="Arama"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">Kubernetes 排错指南：POD【转载】</h1><div class="post-meta"><a href="/2018/05/08/troubleshooting-pod.html#comments" class="comment-count"></a><p><span class="date">May 08, 2018</span><span><a href="/categories/Kubernetes/" class="category">Kubernetes</a></span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span></p></div><div class="post-content"><p>本章介绍 Pod 运行异常的排错方法。</p>
<p>一般来说，无论 Pod 处于什么异常状态，都可以执行以下命令来查看 Pod 的状态</p>
<ul>
<li><code>kubectl get pod &lt;pod-name&gt; -o yaml</code> 查看 Pod 的配置是否正确</li>
<li><code>kubectl describe pod &lt;pod-name&gt;</code> 查看 Pod 的事件</li>
<li><code>kubectl logs &lt;pod-name&gt; [-c &lt;container-name&gt;]</code> 查看容器日志</li>
</ul>
<p>这些事件和日志通常都会有助于排查 Pod 发生的问题。</p>
<h2 id="Pod-一直处于-Pending-状态"><a href="#Pod-一直处于-Pending-状态" class="headerlink" title="Pod 一直处于 Pending 状态"></a>Pod 一直处于 Pending 状态</h2><p>Pending 说明 Pod 还没有调度到某个 Node 上面。可以通过 <code>kubectl describe pod &lt;pod-name&gt;</code> 命令查看到当前 Pod 的事件，进而判断为什么没有调度。如</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe pod mypod</span><br><span class="line">...</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason            Age                From               Message</span><br><span class="line">  ----     ------            ----               ----               -------</span><br><span class="line">  Warning  FailedScheduling  12s (x6 over 27s)  default-scheduler  0/4 nodes are available: 2 Insufficient cpu.</span><br></pre></td></tr></table></figure>
<p>可能的原因包括</p>
<ul>
<li>资源不足，集群内所有的 Node 都不满足该 Pod 请求的 CPU、内存、GPU 或者临时存储空间等资源。解决方法是删除集群内不用的 Pod 或者增加新的 Node。</li>
<li>HostPort 端口已被占用，通常推荐使用 Service 对外开放服务端口</li>
</ul>
<h2 id="Pod-一直处于-Waiting-或-ContainerCreating-状态"><a href="#Pod-一直处于-Waiting-或-ContainerCreating-状态" class="headerlink" title="Pod 一直处于 Waiting 或 ContainerCreating 状态"></a>Pod 一直处于 Waiting 或 ContainerCreating 状态</h2><p>首先还是通过 <code>kubectl describe pod &lt;pod-name&gt;</code> 命令查看到当前 Pod 的事件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n kube-system describe pod nginx-pod</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason                 Age               From               Message</span><br><span class="line">  ----     ------                 ----              ----               -------</span><br><span class="line">  Normal   Scheduled              1m                default-scheduler  Successfully assigned nginx-pod to node1</span><br><span class="line">  Normal   SuccessfulMountVolume  1m                kubelet, gpu13     MountVolume.SetUp succeeded for volume &quot;config-volume&quot;</span><br><span class="line">  Normal   SuccessfulMountVolume  1m                kubelet, gpu13     MountVolume.SetUp succeeded for volume &quot;coredns-token-sxdmc&quot;</span><br><span class="line">  Warning  FailedSync             2s (x4 over 46s)  kubelet, gpu13     Error syncing pod</span><br><span class="line">  Normal   SandboxChanged         1s (x4 over 46s)  kubelet, gpu13     Pod sandbox changed, it will be killed and re-created.</span><br></pre></td></tr></table></figure>
<p>可以发现，该 Pod 的 Sandbox 容器无法正常启动，具体原因需要查看 Kubelet 日志：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ journalctl -u kubelet</span><br><span class="line">...</span><br><span class="line">Mar 14 04:22:04 node1 kubelet[29801]: E0314 04:22:04.649912   29801 cni.go:294] Error adding network: failed to set bridge addr: &quot;cni0&quot; already has an IP address different from 10.244.4.1/24</span><br><span class="line">Mar 14 04:22:04 node1 kubelet[29801]: E0314 04:22:04.649941   29801 cni.go:243] Error while adding to cni network: failed to set bridge addr: &quot;cni0&quot; already has an IP address different from 10.244.4.1/24</span><br><span class="line">Mar 14 04:22:04 node1 kubelet[29801]: W0314 04:22:04.891337   29801 cni.go:258] CNI failed to retrieve network namespace path: Cannot find network namespace for the terminated container &quot;c4fd616cde0e7052c240173541b8543f746e75c17744872aa04fe06f52b5141c&quot;</span><br><span class="line">Mar 14 04:22:05 node1 kubelet[29801]: E0314 04:22:05.965801   29801 remote_runtime.go:91] RunPodSandbox from runtime service failed: rpc error: code = 2 desc = NetworkPlugin cni failed to set up pod &quot;nginx-pod&quot; network: failed to set bridge addr: &quot;cni0&quot; already has an IP address different from 10.244.4.1/24</span><br></pre></td></tr></table></figure>
<p>发现是 cni0 网桥配置了一个不同网段的 IP 地址导致，删除该网桥（网络插件会自动重新创建）即可修复</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ip link set cni0 down</span><br><span class="line">$ brctl delbr cni0</span><br></pre></td></tr></table></figure>
<p>除了以上错误，其他可能的原因还有</p>
<ul>
<li>镜像拉取失败，比如<ul>
<li>配置了错误的镜像</li>
<li>Kubelet 无法访问镜像（国内环境访问 <code>gcr.io</code> 需要特殊处理）</li>
<li>私有镜像的密钥配置错误</li>
<li>镜像太大，拉取超时（可以适当调整 kubelet 的 <code>--image-pull-progress-deadline</code> 和 <code>--runtime-request-timeout</code> 选项）</li>
</ul>
</li>
<li>CNI 网络错误，一般需要检查 CNI 网络插件的配置，比如<ul>
<li>无法配置 Pod 网络</li>
<li>无法分配 IP 地址</li>
</ul>
</li>
<li>容器无法启动，需要检查是否打包了正确的镜像或者是否配置了正确的容器参数</li>
</ul>
<h2 id="Pod-处于-ImagePullBackOff-状态"><a href="#Pod-处于-ImagePullBackOff-状态" class="headerlink" title="Pod 处于 ImagePullBackOff 状态"></a>Pod 处于 ImagePullBackOff 状态</h2><p>这通常是镜像名称配置错误或者私有镜像的密钥配置错误导致。这种情况可以使用 <code>docker pull &lt;image&gt;</code> 来验证镜像是否可以正常拉取。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe pod mypod</span><br><span class="line">...</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason                 Age                From                                Message</span><br><span class="line">  ----     ------                 ----               ----                                -------</span><br><span class="line">  Normal   Scheduled              36s                default-scheduler                   Successfully assigned sh to k8s-agentpool1-38622806-0</span><br><span class="line">  Normal   SuccessfulMountVolume  35s                kubelet, k8s-agentpool1-38622806-0  MountVolume.SetUp succeeded for volume &quot;default-token-n4pn6&quot;</span><br><span class="line">  Normal   Pulling                17s (x2 over 33s)  kubelet, k8s-agentpool1-38622806-0  pulling image &quot;a1pine&quot;</span><br><span class="line">  Warning  Failed                 14s (x2 over 29s)  kubelet, k8s-agentpool1-38622806-0  Failed to pull image &quot;a1pine&quot;: rpc error: code = Unknown desc = Error response from daemon: repository a1pine not found: does not exist or no pull access</span><br><span class="line">  Warning  Failed                 14s (x2 over 29s)  kubelet, k8s-agentpool1-38622806-0  Error: ErrImagePull</span><br><span class="line">  Normal   SandboxChanged         4s (x7 over 28s)   kubelet, k8s-agentpool1-38622806-0  Pod sandbox changed, it will be killed and re-created.</span><br><span class="line">  Normal   BackOff                4s (x5 over 25s)   kubelet, k8s-agentpool1-38622806-0  Back-off pulling image &quot;a1pine&quot;</span><br><span class="line">  Warning  Failed                 1s (x6 over 25s)   kubelet, k8s-agentpool1-38622806-0  Error: ImagePullBackOff</span><br></pre></td></tr></table></figure>
<p>如果是私有镜像，需要首先创建一个 docker-registry 类型的 Secret</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create secret docker-registry my-secret --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAIL</span><br></pre></td></tr></table></figure>
<p>然后在容器中引用这个 Secret</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">private-reg-container</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">&lt;your-private-image&gt;</span></span><br><span class="line"><span class="attr">  imagePullSecrets:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">my-secret</span></span><br></pre></td></tr></table></figure>
<h2 id="Pod-一直处于-CrashLoopBackOff-状态"><a href="#Pod-一直处于-CrashLoopBackOff-状态" class="headerlink" title="Pod 一直处于 CrashLoopBackOff 状态"></a>Pod 一直处于 CrashLoopBackOff 状态</h2><p>CrashLoopBackOff 状态说明容器曾经启动了，但又异常退出了。此时 Pod 的 RestartCounts 通常是大于 0 的，可以先查看一下容器的日志</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe pod &lt;pod-name&gt;</span><br><span class="line">kubectl logs &lt;pod-name&gt;</span><br><span class="line">kubectl logs --previous &lt;pod-name&gt;</span><br></pre></td></tr></table></figure>
<p>这里可以发现一些容器退出的原因，比如</p>
<ul>
<li>容器进程退出</li>
<li>健康检查失败退出</li>
<li>OOMKilled</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe pod mypod</span><br><span class="line">...</span><br><span class="line">Containers:</span><br><span class="line">  sh:</span><br><span class="line">    Container ID:  docker://3f7a2ee0e7e0e16c22090a25f9b6e42b5c06ec049405bc34d3aa183060eb4906</span><br><span class="line">    Image:         alpine</span><br><span class="line">    Image ID:      docker-pullable://alpine@sha256:7b848083f93822dd21b0a2f14a110bd99f6efb4b838d499df6d04a49d0debf8b</span><br><span class="line">    Port:          &lt;none&gt;</span><br><span class="line">    Host Port:     &lt;none&gt;</span><br><span class="line">    State:          Terminated</span><br><span class="line">      Reason:       OOMKilled</span><br><span class="line">      Exit Code:    2</span><br><span class="line">    Last State:     Terminated</span><br><span class="line">      Reason:       OOMKilled</span><br><span class="line">      Exit Code:    2</span><br><span class="line">    Ready:          False</span><br><span class="line">    Restart Count:  3</span><br><span class="line">    Limits:</span><br><span class="line">      cpu:     1</span><br><span class="line">      memory:  1G</span><br><span class="line">    Requests:</span><br><span class="line">      cpu:        100m</span><br><span class="line">      memory:     500M</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>如果此时如果还未发现线索，还可以到容器内执行命令来进一步查看退出原因</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl exec cassandra -- cat /var/log/cassandra/system.log</span><br></pre></td></tr></table></figure>
<p>如果还是没有线索，那就需要 SSH 登录该 Pod 所在的 Node 上，查看 Kubelet 或者 Docker 的日志进一步排查了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Query Node</span><br><span class="line">kubectl get pod &lt;pod-name&gt; -o wide</span><br><span class="line"></span><br><span class="line"># SSH to Node</span><br><span class="line">ssh &lt;username&gt;@&lt;node-name&gt;</span><br></pre></td></tr></table></figure>
<h2 id="Pod-处于-Error-状态"><a href="#Pod-处于-Error-状态" class="headerlink" title="Pod 处于 Error 状态"></a>Pod 处于 Error 状态</h2><p>通常处于 Error 状态说明 Pod 启动过程中发生了错误。常见的原因包括</p>
<ul>
<li>依赖的 ConfigMap、Secret 或者 PV 等不存在</li>
<li>请求的资源超过了管理员设置的限制，比如超过了 LimitRange 等</li>
<li>违反集群的安全策略，比如违反了 PodSecurityPolicy 等</li>
<li>容器无权操作集群内的资源，比如开启 RBAC 后，需要为 ServiceAccount 配置角色绑定</li>
</ul>
<h2 id="Pod-处于-Terminating-或-Unknown-状态"><a href="#Pod-处于-Terminating-或-Unknown-状态" class="headerlink" title="Pod 处于 Terminating 或 Unknown 状态"></a>Pod 处于 Terminating 或 Unknown 状态</h2><p>从 v1.5 开始，Kubernetes 不会因为 Node 失联而删除其上正在运行的 Pod，而是将其标记为 Terminating 或 Unknown 状态。想要删除这些状态的 Pod 有三种方法：</p>
<ul>
<li>从集群中删除该 Node。使用公有云时，kube-controller-manager 会在 VM 删除后自动删除对应的 Node。而在物理机部署的集群中，需要管理员手动删除 Node（如 <code>kubectl delete node &lt;node-name&gt;</code>。</li>
<li>Node 恢复正常。Kubelet 会重新跟 kube-apiserver 通信确认这些 Pod 的期待状态，进而再决定删除或者继续运行这些 Pod。</li>
<li>用户强制删除。用户可以执行 <code>kubectl delete pods &lt;pod&gt; --grace-period=0 --force</code> 强制删除 Pod。除非明确知道 Pod 的确处于停止状态（比如 Node 所在 VM 或物理机已经关机），否则不建议使用该方法。特别是 StatefulSet 管理的 Pod，强制删除容易导致脑裂或者数据丢失等问题。</li>
</ul>
<p>如果 Kubelet 是以 Docker 容器的形式运行的，此时 kubelet 日志中可能会发现<a href="https://github.com/kubernetes/kubernetes/issues/51835" target="_blank" rel="noopener">如下的错误</a>：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"log"</span>:<span class="string">"I0926 19:59:07.162477   54420 kubelet.go:1894] SyncLoop (DELETE, \"api\"): \"billcenter-737844550-26z3w_meipu(30f3ffec-a29f-11e7-b693-246e9607517c)\"\n"</span>,<span class="attr">"stream"</span>:<span class="string">"stderr"</span>,<span class="attr">"time"</span>:<span class="string">"2017-09-26T11:59:07.162748656Z"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"log"</span>:<span class="string">"I0926 19:59:39.977126   54420 reconciler.go:186] operationExecutor.UnmountVolume started for volume \"default-token-6tpnm\" (UniqueName: \"kubernetes.io/secret/30f3ffec-a29f-11e7-b693-246e9607517c-default-token-6tpnm\") pod \"30f3ffec-a29f-11e7-b693-246e9607517c\" (UID: \"30f3ffec-a29f-11e7-b693-246e9607517c\") \n"</span>,<span class="attr">"stream"</span>:<span class="string">"stderr"</span>,<span class="attr">"time"</span>:<span class="string">"2017-09-26T11:59:39.977438174Z"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"log"</span>:<span class="string">"E0926 19:59:39.977461   54420 nestedpendingoperations.go:262] Operation for \"\\\"kubernetes.io/secret/30f3ffec-a29f-11e7-b693-246e9607517c-default-token-6tpnm\\\" (\\\"30f3ffec-a29f-11e7-b693-246e9607517c\\\")\" failed. No retries permitted until 2017-09-26 19:59:41.977419403 +0800 CST (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume \"default-token-6tpnm\" (UniqueName: \"kubernetes.io/secret/30f3ffec-a29f-11e7-b693-246e9607517c-default-token-6tpnm\") pod \"30f3ffec-a29f-11e7-b693-246e9607517c\" (UID: \"30f3ffec-a29f-11e7-b693-246e9607517c\") : remove /var/lib/kubelet/pods/30f3ffec-a29f-11e7-b693-246e9607517c/volumes/kubernetes.io~secret/default-token-6tpnm: device or resource busy\n"</span>,<span class="attr">"stream"</span>:<span class="string">"stderr"</span>,<span class="attr">"time"</span>:<span class="string">"2017-09-26T11:59:39.977728079Z"</span>&#125;</span><br></pre></td></tr></table></figure>
<p>如果是这种情况，则需要给 kubelet 容器设置 <code>--containerized</code> 参数并传入以下的存储卷</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 以使用 calico 网络插件为例</span><br><span class="line">      -v /:/rootfs:ro,shared \</span><br><span class="line">      -v /sys:/sys:ro \</span><br><span class="line">      -v /dev:/dev:rw \</span><br><span class="line">      -v /var/log:/var/log:rw \</span><br><span class="line">      -v /run/calico/:/run/calico/:rw \</span><br><span class="line">      -v /run/docker/:/run/docker/:rw \</span><br><span class="line">      -v /run/docker.sock:/run/docker.sock:rw \</span><br><span class="line">      -v /usr/lib/os-release:/etc/os-release \</span><br><span class="line">      -v /usr/share/ca-certificates/:/etc/ssl/certs \</span><br><span class="line">      -v /var/lib/docker/:/var/lib/docker:rw,shared \</span><br><span class="line">      -v /var/lib/kubelet/:/var/lib/kubelet:rw,shared \</span><br><span class="line">      -v /etc/kubernetes/ssl/:/etc/kubernetes/ssl/ \</span><br><span class="line">      -v /etc/kubernetes/config/:/etc/kubernetes/config/ \</span><br><span class="line">      -v /etc/cni/net.d/:/etc/cni/net.d/ \</span><br><span class="line">      -v /opt/cni/bin/:/opt/cni/bin/ \</span><br></pre></td></tr></table></figure>
<h2 id="Pod-行为异常"><a href="#Pod-行为异常" class="headerlink" title="Pod 行为异常"></a>Pod 行为异常</h2><p>这里所说的行为异常是指 Pod 没有按预期的行为执行，比如没有运行 podSpec 里面设置的命令行参数。这一般是 podSpec yaml 文件内容有误，可以尝试使用 <code>--validate</code> 参数重建容器，比如</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete pod mypod</span><br><span class="line">kubectl create --validate -f mypod.yaml</span><br></pre></td></tr></table></figure>
<p>也可以查看创建后的 podSpec 是否是对的，比如</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod mypod -o yaml</span><br></pre></td></tr></table></figure>
<h2 id="修改静态-Pod-的-Manifest-后未自动重建"><a href="#修改静态-Pod-的-Manifest-后未自动重建" class="headerlink" title="修改静态 Pod 的 Manifest 后未自动重建"></a>修改静态 Pod 的 Manifest 后未自动重建</h2><p>Kubelet 使用 inotify 机制检测 <code>/etc/kubernetes/manifests</code> 目录（可通过 Kubelet 的 <code>--pod-manifest-path</code> 选项指定）中静态 Pod 的变化，并在文件发生变化后重新创建相应的 Pod。但有时也会发生修改静态 Pod 的 Manifest 后未自动创建新 Pod 的情景，此时一个简单的修复方法是重启 Kubelet。</p>
<h3 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h3><ul>
<li><a href="https://kubernetes.io/docs/tasks/debug-application-cluster/debug-application/" target="_blank" rel="noopener">Troubleshoot Applications</a></li>
</ul>
</div><div class="tags"><a href="/tags/Kubernetes-排错指南/">Kubernetes 排错指南</a></div><div class="post-share"><div class="bdsharebuttonbox"><span style="float:left;line-height: 28px;height: 28px;font-size:16px;font-weight:blod">分享到：</span><a href="#" data-cmd="more" class="bds_more"></a><a href="#" data-cmd="mshare" title="分享到一键分享" class="bds_mshare"></a><a href="#" data-cmd="fbook" title="分享到Facebook" class="bds_fbook"></a><a href="#" data-cmd="twi" title="分享到Twitter" class="bds_twi"></a><a href="#" data-cmd="linkedin" title="分享到linkedin" class="bds_linkedin"></a><a href="#" data-cmd="youdao" title="分享到有道云笔记" class="bds_youdao"></a><a href="#" data-cmd="evernotecn" title="分享到印象笔记" class="bds_evernotecn"></a><a href="#" data-cmd="weixin" title="分享到微信" class="bds_weixin"></a><a href="#" data-cmd="qzone" title="分享到QQ空间" class="bds_qzone"></a><a href="#" data-cmd="tsina" title="分享到新浪微博" class="bds_tsina"></a></div></div><div class="post-nav"><a href="/2018/05/12/comparison-between-calico-and-flannel.html" class="pre">calico与flannel对比</a><a href="/2018/05/07/troubleshooting-cluster.html" class="next">Kubernetes 排错指南：集群【转载】</a></div><div id="comments"></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Pod-一直处于-Pending-状态"><span class="toc-text">Pod 一直处于 Pending 状态</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pod-一直处于-Waiting-或-ContainerCreating-状态"><span class="toc-text">Pod 一直处于 Waiting 或 ContainerCreating 状态</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pod-处于-ImagePullBackOff-状态"><span class="toc-text">Pod 处于 ImagePullBackOff 状态</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pod-一直处于-CrashLoopBackOff-状态"><span class="toc-text">Pod 一直处于 CrashLoopBackOff 状态</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pod-处于-Error-状态"><span class="toc-text">Pod 处于 Error 状态</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pod-处于-Terminating-或-Unknown-状态"><span class="toc-text">Pod 处于 Terminating 或 Unknown 状态</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pod-行为异常"><span class="toc-text">Pod 行为异常</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#修改静态-Pod-的-Manifest-后未自动重建"><span class="toc-text">修改静态 Pod 的 Manifest 后未自动重建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#参考文档"><span class="toc-text">参考文档</span></a></li></ol></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/05/12/comparison-between-calico-and-flannel.html">calico与flannel对比</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/08/troubleshooting-pod.html">Kubernetes 排错指南：POD【转载】</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/07/troubleshooting-cluster.html">Kubernetes 排错指南：集群【转载】</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/07/troubleshooting-index.html">Kubernetes 排错指南：开篇【转载】</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/18/top-5-kubernetes-best-practices.html">五大 Kubernetes 最佳实践【转载】</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/02/kubernetes-19-conflict-with-centos7.html">Kubernetes 1.9 与 CentOS 7 内核兼容问题【转载】</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/01/performance-tuning-overview.html">性能调优概述</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/31/simplifying-microservices-with-istio-in-kubernetes-3.html">使用Istio简化微服务系列三：如何才能做“金丝雀部署”，并通过Istio增加流量？【转载】</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/31/simplifying-microservices-with-istio-in-kubernetes-2.html">使用Istio简化微服务系列二：如何通过HTTPS与外部服务进行通信？【转载】</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/31/simplifying-microservices-with-istio-in-kubernetes-1.html">使用Istio简化微服务系列一：如何用Isito解决Spring Cloud Netflix部署微服务的挑战?【转载】</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/">Docker</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Jenkins/">Jenkins</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kubernetes/">Kubernetes</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/微服务/">微服务</a><span class="category-list-count">11</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/Istio简化微服务系列/" style="font-size: 15px;">Istio简化微服务系列</a> <a href="/tags/微服务入门系列/" style="font-size: 15px;">微服务入门系列</a> <a href="/tags/Pipeline/" style="font-size: 15px;">Pipeline</a> <a href="/tags/Jenkins/" style="font-size: 15px;">Jenkins</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/亲和性/" style="font-size: 15px;">亲和性</a> <a href="/tags/Kubernetes/" style="font-size: 15px;">Kubernetes</a> <a href="/tags/性能调优/" style="font-size: 15px;">性能调优</a> <a href="/tags/Spring-Cloud/" style="font-size: 15px;">Spring Cloud</a> <a href="/tags/Dubbo-Service-Mesh-微服务-ZooKeeper/" style="font-size: 15px;">Dubbo,Service Mesh,微服务,ZooKeeper</a> <a href="/tags/Kubernetes-排错指南/" style="font-size: 15px;">Kubernetes 排错指南</a> <a href="/tags/微服务拆分/" style="font-size: 15px;">微服务拆分</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">五月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a></li></ul></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">Baidu Site Haritası</a> |  <a href="/atom.xml">订阅</a> |  <a href="/about/">关于</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次</p><p><span> Copyright &copy;<a href="/." rel="nofollow">Cloudpanl.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?8c06a0cc670571138e4a33bce0d3167a";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/js/search.json.js?v=2.0.1"></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.1" async></script><script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":["mshare","weixin","tsina","qzone","linkedin","fbook","twi","print","renren","sqq","evernotecn","bdysc","tqq","tqf","bdxc","kaixin001","tieba","douban","bdhome","thx","ibaidu","meilishuo","mogujie","diandian","huaban","duitang","hx","fx","youdao","sdo","qingbiji","people","xinhua","mail","isohu","yaolan","wealink","ty","iguba","h163","copy"],"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{},"image":{"viewList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"]}};with(document)0[(getElementsByTagName('head')[0]||head).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script></body></html>